{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f3c4979",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-10-07T21:09:07.985767Z",
     "iopub.status.busy": "2023-10-07T21:09:07.985469Z",
     "iopub.status.idle": "2023-10-07T21:09:13.110066Z",
     "shell.execute_reply": "2023-10-07T21:09:13.109145Z"
    },
    "papermill": {
     "duration": 5.131156,
     "end_time": "2023-10-07T21:09:13.112272",
     "exception": false,
     "start_time": "2023-10-07T21:09:07.981116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pathlib\n",
    "import gc\n",
    "import math\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, BatchSampler, RandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eca37e92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T21:09:13.120713Z",
     "iopub.status.busy": "2023-10-07T21:09:13.119534Z",
     "iopub.status.idle": "2023-10-07T21:09:13.188698Z",
     "shell.execute_reply": "2023-10-07T21:09:13.187697Z"
    },
    "papermill": {
     "duration": 0.075466,
     "end_time": "2023-10-07T21:09:13.190686",
     "exception": false,
     "start_time": "2023-10-07T21:09:13.115220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "INPUT_PATH = pathlib.Path('/kaggle/input/stanford-ribonanza-rna-folding-converted')\n",
    "MODEL_PATH = pathlib.Path('/kaggle/input/rna-folding-model/')\n",
    "WORKING_PATH = pathlib.Path('/kaggle/working/')\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "232349ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T21:09:13.197206Z",
     "iopub.status.busy": "2023-10-07T21:09:13.196561Z",
     "iopub.status.idle": "2023-10-07T21:09:38.088502Z",
     "shell.execute_reply": "2023-10-07T21:09:38.087480Z"
    },
    "papermill": {
     "duration": 24.897418,
     "end_time": "2023-10-07T21:09:38.090710",
     "exception": false,
     "start_time": "2023-10-07T21:09:13.193292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_df = pd.read_parquet(INPUT_PATH/\"train_data.parquet\")\n",
    "test_df = pd.read_parquet(INPUT_PATH/\"test_sequences.parquet\")\n",
    "\n",
    "df_2A3 = full_df[full_df.experiment_type =='2A3_MaP'].reset_index(drop=True)\n",
    "df_DMS = full_df[full_df.experiment_type =='DMS_MaP'].reset_index(drop=True)\n",
    "train_2A3, val_2A3, train_DMS, val_DMS= train_test_split(df_2A3, df_DMS, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1d2e902",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T21:09:38.097397Z",
     "iopub.status.busy": "2023-10-07T21:09:38.097099Z",
     "iopub.status.idle": "2023-10-07T21:09:38.106814Z",
     "shell.execute_reply": "2023-10-07T21:09:38.105854Z"
    },
    "papermill": {
     "duration": 0.015077,
     "end_time": "2023-10-07T21:09:38.108496",
     "exception": false,
     "start_time": "2023-10-07T21:09:38.093419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RNA_Dataset(Dataset):\n",
    "    def __init__(self, df_2A3, df_DMS):\n",
    "        # filter noisy data for now\n",
    "        predicate = (df_2A3.SN_filter.values > 0) & (df_DMS.SN_filter.values > 0)\n",
    "        df_2A3 = df_2A3[predicate].reset_index(drop=True)\n",
    "        df_DMS = df_DMS[predicate].reset_index(drop=True)\n",
    "        \n",
    "        self.seq_map = {'A':1, 'C':2, 'G':3, 'U':4}\n",
    "        self.seqs = df_2A3.sequence.values\n",
    "        self.react_2A3 = df_2A3[[c for c in df_2A3.columns if \\\n",
    "                                 'reactivity_0' in c]].values\n",
    "        self.react_DMS = df_DMS[[c for c in df_DMS.columns if \\\n",
    "                                 'reactivity_0' in c]].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.seqs)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seqs[idx]\n",
    "        seq_idx = torch.tensor([self.seq_map[s] for s in seq], dtype=torch.long)\n",
    "        labels = torch.tensor(np.stack([self.react_2A3[idx],\n",
    "                                           self.react_DMS[idx]], -1), dtype=torch.float32)\n",
    "        return seq_idx, labels\n",
    "    \n",
    "# Useful for sampling batches of similar lengths to minimize padding\n",
    "class GroupLengthBatchSampler(BatchSampler):\n",
    "    def __iter__(self):\n",
    "        dataset = self.sampler.data_source\n",
    "        indices = [idx for idx in self.sampler]\n",
    "\n",
    "        step = 100 * self.batch_size\n",
    "        for i in range(0, len(dataset), step):\n",
    "            pool = indices[i:i+step]\n",
    "            pool = sorted(pool, key=lambda x: len(dataset[x][0]))\n",
    "            for j in range(0, len(pool), self.batch_size):\n",
    "                if j + self.batch_size > len(pool): # assume drop_last=True\n",
    "                    break\n",
    "                yield pool[j:j+self.batch_size]\n",
    "        \n",
    "def collate_fn(data):\n",
    "    seq_idx, labels = zip(*data)\n",
    "    padded_seqs = nn.utils.rnn.pad_sequence(seq_idx, batch_first=True)\n",
    "    B, T = padded_seqs.shape\n",
    "    labels = torch.stack(labels)[:, :T, :]\n",
    "    return padded_seqs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cf4e9f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T21:09:38.114588Z",
     "iopub.status.busy": "2023-10-07T21:09:38.114341Z",
     "iopub.status.idle": "2023-10-07T21:09:38.123017Z",
     "shell.execute_reply": "2023-10-07T21:09:38.122054Z"
    },
    "papermill": {
     "duration": 0.013706,
     "end_time": "2023-10-07T21:09:38.124675",
     "exception": false,
     "start_time": "2023-10-07T21:09:38.110969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab_size = 5 # the 4 bases + padding\n",
    "emb_dim = 256\n",
    "num_layers = 12\n",
    "nhead=8\n",
    "batch_size = 128\n",
    "itos = {0: \"<PAD>\", 1: \"A\", 2: \"C\", 3: \"G\", 4: \"U\"}\n",
    "\n",
    "# we have to use fixed Positions because training data is \n",
    "# shorter than test data\n",
    "class PositionEncoding(nn.Module):\n",
    "    def __init__(self, emb_dim, max_len=512):\n",
    "        super().__init__()\n",
    "        positions = torch.arange(max_len).unsqueeze(1)\n",
    "        evens = torch.arange(0, emb_dim, 2)\n",
    "        frequencies = torch.exp(evens * (-math.log(10_000)/emb_dim))\n",
    "        pos_embs = torch.zeros(max_len, emb_dim)\n",
    "        pos_embs[:, 0::2] = torch.sin(positions * frequencies)\n",
    "        pos_embs[:, 1::2] = torch.cos(positions * frequencies)\n",
    "        self.register_buffer('pos_emb', pos_embs)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.pos_emb[:x.size(1)]\n",
    "                \n",
    "class RNA_Transformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.pos_emb = PositionEncoding(emb_dim)\n",
    "        enc_layer = nn.TransformerEncoderLayer(emb_dim, nhead,\n",
    "                                               dim_feedforward=4*emb_dim,\n",
    "                                               batch_first=True, norm_first=True,\n",
    "                                               activation=\"gelu\")\n",
    "        self.encoder = nn.TransformerEncoder(enc_layer, num_layers)\n",
    "        self.regression_head = nn.Linear(emb_dim, 2)\n",
    "        \n",
    "    def forward(self, x, targets=None):\n",
    "        B, T = x.shape\n",
    "        z = self.token_emb(x)\n",
    "        z = self.pos_emb(z)\n",
    "        z = self.encoder(z)\n",
    "        preds = self.regression_head(z)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            preds = preds.view(B*T, 2)\n",
    "            targets = targets.contiguous().view(B*T, 2).clamp(0, 1)\n",
    "            loss = F.l1_loss(preds, targets, reduction='none')\n",
    "            loss = loss[~loss.isnan()].mean()\n",
    "        return preds, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "887a7045",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T21:09:38.130244Z",
     "iopub.status.busy": "2023-10-07T21:09:38.129962Z",
     "iopub.status.idle": "2023-10-07T21:09:40.210109Z",
     "shell.execute_reply": "2023-10-07T21:09:40.209168Z"
    },
    "papermill": {
     "duration": 2.08534,
     "end_time": "2023-10-07T21:09:40.212271",
     "exception": false,
     "start_time": "2023-10-07T21:09:38.126931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = RNA_Dataset(train_2A3, train_DMS), RNA_Dataset(val_2A3, val_DMS)\n",
    "trainsampler = GroupLengthBatchSampler(RandomSampler(train_dataset), batch_size, drop_last=True)\n",
    "valsampler = GroupLengthBatchSampler(RandomSampler(val_dataset), batch_size, drop_last=True)\n",
    "trainloader = DataLoader(train_dataset, batch_sampler=trainsampler, collate_fn=collate_fn)\n",
    "validloader = DataLoader(val_dataset, batch_sampler=valsampler, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "177d6096",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T21:09:40.219264Z",
     "iopub.status.busy": "2023-10-07T21:09:40.218383Z",
     "iopub.status.idle": "2023-10-07T21:09:43.626711Z",
     "shell.execute_reply": "2023-10-07T21:09:43.625753Z"
    },
    "papermill": {
     "duration": 3.413661,
     "end_time": "2023-10-07T21:09:43.628767",
     "exception": false,
     "start_time": "2023-10-07T21:09:40.215106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = RNA_Transformer()#torch.load(MODEL_PATH/\"best_model.pth\", map_location=device)\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "563fdedc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T21:09:43.635035Z",
     "iopub.status.busy": "2023-10-07T21:09:43.634727Z",
     "iopub.status.idle": "2023-10-07T21:09:43.639906Z",
     "shell.execute_reply": "2023-10-07T21:09:43.638897Z"
    },
    "papermill": {
     "duration": 0.010205,
     "end_time": "2023-10-07T21:09:43.641686",
     "exception": false,
     "start_time": "2023-10-07T21:09:43.631481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4)\n",
    "train_steps = epochs * len(trainloader)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b44d4c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T21:09:43.647466Z",
     "iopub.status.busy": "2023-10-07T21:09:43.647198Z",
     "iopub.status.idle": "2023-10-08T01:37:27.716694Z",
     "shell.execute_reply": "2023-10-08T01:37:27.715669Z"
    },
    "papermill": {
     "duration": 16064.074415,
     "end_time": "2023-10-08T01:37:27.718442",
     "exception": false,
     "start_time": "2023-10-07T21:09:43.644027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with 9,478,914 parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1274/1274 [08:41<00:00,  2.44it/s, Loss=0.238]\n",
      "100%|██████████| 141/141 [00:15<00:00,  9.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.2295912653207779\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1274/1274 [08:38<00:00,  2.46it/s, Loss=0.223]\n",
      "100%|██████████| 141/141 [00:15<00:00,  9.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.21700850129127502\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1274/1274 [08:38<00:00,  2.45it/s, Loss=0.214]\n",
      "100%|██████████| 141/141 [00:15<00:00,  9.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.20379909873008728\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1274/1274 [08:39<00:00,  2.45it/s, Loss=0.197]\n",
      "100%|██████████| 141/141 [00:15<00:00,  9.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.19069397449493408\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1274/1274 [08:39<00:00,  2.45it/s, Loss=0.188]\n",
      "100%|██████████| 141/141 [00:15<00:00,  9.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1814122349023819\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1274/1274 [08:39<00:00,  2.45it/s, Loss=0.181]\n",
      "100%|██████████| 141/141 [00:15<00:00,  9.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.17464832961559296\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1274/1274 [08:39<00:00,  2.45it/s, Loss=0.174]\n",
      "100%|██████████| 141/141 [00:15<00:00,  9.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.16944968700408936\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1274/1274 [08:39<00:00,  2.45it/s, Loss=0.168]\n",
      "100%|██████████| 141/141 [00:15<00:00,  9.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.16281795501708984\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1274/1274 [08:39<00:00,  2.45it/s, Loss=0.162]\n",
      "100%|██████████| 141/141 [00:15<00:00,  9.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.15869954228401184\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1274/1274 [08:40<00:00,  2.45it/s, Loss=0.158]\n",
      "100%|██████████| 141/141 [00:15<00:00,  9.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.15619315207004547\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 1274/1274 [08:39<00:00,  2.45it/s, Loss=0.155]\n",
      "100%|██████████| 141/141 [00:15<00:00,  9.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.15233047306537628\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 1274/1274 [08:39<00:00,  2.45it/s, Loss=0.152]\n",
      "100%|██████████| 141/141 [00:15<00:00,  9.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.15019436180591583\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 1274/1274 [08:39<00:00,  2.45it/s, Loss=0.149]\n",
      "100%|██████████| 141/141 [00:15<00:00,  8.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1489133983850479\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 1274/1274 [08:39<00:00,  2.45it/s, Loss=0.148]\n",
      "100%|██████████| 141/141 [00:15<00:00,  9.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.14711876213550568\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 1274/1274 [08:39<00:00,  2.45it/s, Loss=0.146]\n",
      "100%|██████████| 141/141 [00:15<00:00,  9.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1459328681230545\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 1274/1274 [08:39<00:00,  2.45it/s, Loss=0.144]\n",
      "100%|██████████| 141/141 [00:15<00:00,  8.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1447269171476364\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 1274/1274 [08:40<00:00,  2.45it/s, Loss=0.142]\n",
      "100%|██████████| 141/141 [00:15<00:00,  9.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1437838226556778\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 1274/1274 [08:40<00:00,  2.45it/s, Loss=0.142]\n",
      "100%|██████████| 141/141 [00:15<00:00,  8.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.14321470260620117\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 1274/1274 [08:39<00:00,  2.45it/s, Loss=0.14]\n",
      "100%|██████████| 141/141 [00:15<00:00,  8.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.14129072427749634\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 1274/1274 [08:39<00:00,  2.45it/s, Loss=0.139]\n",
      "100%|██████████| 141/141 [00:15<00:00,  8.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.14126606285572052\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 1274/1274 [08:39<00:00,  2.45it/s, Loss=0.138]\n",
      "100%|██████████| 141/141 [00:15<00:00,  8.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.14036917686462402\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 1274/1274 [08:39<00:00,  2.45it/s, Loss=0.137]\n",
      "100%|██████████| 141/141 [00:15<00:00,  9.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.13932764530181885\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 1274/1274 [08:40<00:00,  2.45it/s, Loss=0.136]\n",
      "100%|██████████| 141/141 [00:15<00:00,  9.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1393185406923294\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 1274/1274 [08:39<00:00,  2.45it/s, Loss=0.135]\n",
      "100%|██████████| 141/141 [00:15<00:00,  9.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.13920028507709503\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 1274/1274 [08:41<00:00,  2.45it/s, Loss=0.135]\n",
      "100%|██████████| 141/141 [00:15<00:00,  9.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.13875442743301392\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 1274/1274 [08:40<00:00,  2.45it/s, Loss=0.134]\n",
      "100%|██████████| 141/141 [00:15<00:00,  9.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1386735588312149\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 1274/1274 [08:40<00:00,  2.45it/s, Loss=0.134]\n",
      "100%|██████████| 141/141 [00:15<00:00,  8.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.13848300278186798\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 1274/1274 [08:40<00:00,  2.45it/s, Loss=0.134]\n",
      "100%|██████████| 141/141 [00:16<00:00,  8.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1384992003440857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 1274/1274 [08:38<00:00,  2.46it/s, Loss=0.134]\n",
      "100%|██████████| 141/141 [00:15<00:00,  9.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.13834603130817413\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 1274/1274 [08:38<00:00,  2.46it/s, Loss=0.134]\n",
      "100%|██████████| 141/141 [00:15<00:00,  9.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.13835878670215607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def eval_loop():\n",
    "    model.eval()\n",
    "    losses = torch.zeros(len(validloader))\n",
    "    for i, (x, y) in tqdm(enumerate(validloader), total=len(validloader)):\n",
    "        _, loss = model(x.to(device), y.to(device))\n",
    "        losses[i] = loss.item()\n",
    "    model.train()\n",
    "    val_loss = losses.mean().item()\n",
    "    print(f\"Val Loss: {val_loss}\")\n",
    "    return val_loss\n",
    "            \n",
    "eval_distance = 500\n",
    "min_loss = 0.3\n",
    "n_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Training model with {n_params:,} parameters...\")\n",
    "loss_dict = {\"train_loss\": [], \"val_loss\": []}\n",
    "for epoch in range(epochs):\n",
    "    losses = torch.zeros(len(trainloader))\n",
    "    pbar = tqdm(enumerate(trainloader), total=len(trainloader))\n",
    "    pbar.set_description(f\"Epoch {epoch}\")\n",
    "    for i, (x, y) in pbar:\n",
    "        _, loss = model(x.to(device), y.to(device))\n",
    "        losses[i] = loss.item()\n",
    "        \n",
    "        if i >= eval_distance and i % eval_distance == 0:\n",
    "            train_loss = losses[i-eval_distance:i].mean().item()\n",
    "            pbar.set_postfix({\"Loss\":  train_loss})\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 3.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    val_loss = eval_loop()\n",
    "    loss_dict[\"train_loss\"].append(train_loss)\n",
    "    loss_dict[\"val_loss\"].append(val_loss)\n",
    "    if min_loss > val_loss:\n",
    "        print(\"Saving new best model...\")\n",
    "        min_loss = val_loss\n",
    "        torch.save(model, WORKING_PATH/\"best_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1015168c",
   "metadata": {
    "papermill": {
     "duration": 2.03319,
     "end_time": "2023-10-08T01:37:31.669168",
     "exception": false,
     "start_time": "2023-10-08T01:37:29.635978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 16110.973646,
   "end_time": "2023-10-08T01:37:35.904092",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-07T21:09:04.930446",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
