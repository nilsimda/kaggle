{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95225837",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-10-08T14:50:14.657753Z",
     "iopub.status.busy": "2023-10-08T14:50:14.657108Z",
     "iopub.status.idle": "2023-10-08T14:50:19.133116Z",
     "shell.execute_reply": "2023-10-08T14:50:19.132116Z"
    },
    "papermill": {
     "duration": 4.481904,
     "end_time": "2023-10-08T14:50:19.135420",
     "exception": false,
     "start_time": "2023-10-08T14:50:14.653516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pathlib\n",
    "import gc\n",
    "import math\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, BatchSampler, RandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b63c4d58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T14:50:19.143825Z",
     "iopub.status.busy": "2023-10-08T14:50:19.143394Z",
     "iopub.status.idle": "2023-10-08T14:50:19.209702Z",
     "shell.execute_reply": "2023-10-08T14:50:19.208886Z"
    },
    "papermill": {
     "duration": 0.07177,
     "end_time": "2023-10-08T14:50:19.211363",
     "exception": false,
     "start_time": "2023-10-08T14:50:19.139593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "INPUT_PATH = pathlib.Path('/kaggle/input/stanford-ribonanza-rna-folding-converted')\n",
    "MODEL_PATH = pathlib.Path('/kaggle/input/rna-folding-model/')\n",
    "WORKING_PATH = pathlib.Path('/kaggle/working/')\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6e37da6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T14:50:19.217079Z",
     "iopub.status.busy": "2023-10-08T14:50:19.216575Z",
     "iopub.status.idle": "2023-10-08T14:50:44.342676Z",
     "shell.execute_reply": "2023-10-08T14:50:44.341692Z"
    },
    "papermill": {
     "duration": 25.131301,
     "end_time": "2023-10-08T14:50:44.344956",
     "exception": false,
     "start_time": "2023-10-08T14:50:19.213655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_df = pd.read_parquet(INPUT_PATH/\"train_data.parquet\")\n",
    "test_df = pd.read_parquet(INPUT_PATH/\"test_sequences.parquet\")\n",
    "\n",
    "df_2A3 = full_df[full_df.experiment_type =='2A3_MaP'].reset_index(drop=True)\n",
    "df_DMS = full_df[full_df.experiment_type =='DMS_MaP'].reset_index(drop=True)\n",
    "train_2A3, val_2A3, train_DMS, val_DMS= train_test_split(df_2A3, df_DMS, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98484784",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T14:50:44.351505Z",
     "iopub.status.busy": "2023-10-08T14:50:44.350931Z",
     "iopub.status.idle": "2023-10-08T14:50:44.360683Z",
     "shell.execute_reply": "2023-10-08T14:50:44.359875Z"
    },
    "papermill": {
     "duration": 0.014929,
     "end_time": "2023-10-08T14:50:44.362345",
     "exception": false,
     "start_time": "2023-10-08T14:50:44.347416",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RNA_Dataset(Dataset):\n",
    "    def __init__(self, df_2A3, df_DMS):\n",
    "        # filter noisy data for now\n",
    "        predicate = (df_2A3.SN_filter.values > 0) & (df_DMS.SN_filter.values > 0)\n",
    "        df_2A3 = df_2A3[predicate].reset_index(drop=True)\n",
    "        df_DMS = df_DMS[predicate].reset_index(drop=True)\n",
    "        \n",
    "        self.seq_map = {'A':1, 'C':2, 'G':3, 'U':4}\n",
    "        self.seqs = df_2A3.sequence.values\n",
    "        self.react_2A3 = df_2A3[[c for c in df_2A3.columns if \\\n",
    "                                 'reactivity_0' in c]].values\n",
    "        self.react_DMS = df_DMS[[c for c in df_DMS.columns if \\\n",
    "                                 'reactivity_0' in c]].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.seqs)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seqs[idx]\n",
    "        seq_idx = torch.tensor([self.seq_map[s] for s in seq], dtype=torch.long)\n",
    "        labels = torch.tensor(np.stack([self.react_2A3[idx],\n",
    "                                           self.react_DMS[idx]], -1), dtype=torch.float32)\n",
    "        return seq_idx, labels\n",
    "    \n",
    "# Useful for sampling batches of similar lengths to minimize padding\n",
    "class GroupLengthBatchSampler(BatchSampler):\n",
    "    def __iter__(self):\n",
    "        dataset = self.sampler.data_source\n",
    "        indices = [idx for idx in self.sampler]\n",
    "\n",
    "        step = 100 * self.batch_size\n",
    "        for i in range(0, len(dataset), step):\n",
    "            pool = indices[i:i+step]\n",
    "            pool = sorted(pool, key=lambda x: len(dataset[x][0]))\n",
    "            for j in range(0, len(pool), self.batch_size):\n",
    "                if j + self.batch_size > len(pool): # assume drop_last=True\n",
    "                    break\n",
    "                yield pool[j:j+self.batch_size]\n",
    "        \n",
    "def collate_fn(data):\n",
    "    seq_idx, labels = zip(*data)\n",
    "    padded_seqs = nn.utils.rnn.pad_sequence(seq_idx, batch_first=True)\n",
    "    B, T = padded_seqs.shape\n",
    "    labels = torch.stack(labels)[:, :T, :]\n",
    "    return padded_seqs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c00a42b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T14:50:44.367836Z",
     "iopub.status.busy": "2023-10-08T14:50:44.367572Z",
     "iopub.status.idle": "2023-10-08T14:50:44.376122Z",
     "shell.execute_reply": "2023-10-08T14:50:44.375315Z"
    },
    "papermill": {
     "duration": 0.013297,
     "end_time": "2023-10-08T14:50:44.377730",
     "exception": false,
     "start_time": "2023-10-08T14:50:44.364433",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab_size = 5 # the 4 bases + padding\n",
    "emb_dim = 256\n",
    "num_layers = 12\n",
    "nhead=8\n",
    "batch_size = 128\n",
    "itos = {0: \"<PAD>\", 1: \"A\", 2: \"C\", 3: \"G\", 4: \"U\"}\n",
    "\n",
    "# we have to use fixed Positions because training data is \n",
    "# shorter than test data\n",
    "class PositionEncoding(nn.Module):\n",
    "    def __init__(self, emb_dim, max_len=512):\n",
    "        super().__init__()\n",
    "        positions = torch.arange(max_len).unsqueeze(1)\n",
    "        evens = torch.arange(0, emb_dim, 2)\n",
    "        frequencies = torch.exp(evens * (-math.log(10_000)/emb_dim))\n",
    "        pos_embs = torch.zeros(max_len, emb_dim)\n",
    "        pos_embs[:, 0::2] = torch.sin(positions * frequencies)\n",
    "        pos_embs[:, 1::2] = torch.cos(positions * frequencies)\n",
    "        self.register_buffer('pos_emb', pos_embs)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.pos_emb[:x.size(1)]\n",
    "                \n",
    "class RNA_Transformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.pos_emb = PositionEncoding(emb_dim)\n",
    "        enc_layer = nn.TransformerEncoderLayer(emb_dim, nhead,\n",
    "                                               dim_feedforward=4*emb_dim,\n",
    "                                               batch_first=True, norm_first=True,\n",
    "                                               activation=\"gelu\")\n",
    "        self.encoder = nn.TransformerEncoder(enc_layer, num_layers)\n",
    "        self.regression_head = nn.Linear(emb_dim, 2)\n",
    "        \n",
    "    def forward(self, x, targets=None):\n",
    "        B, T = x.shape\n",
    "        z = self.token_emb(x)\n",
    "        z = self.pos_emb(z)\n",
    "        z = self.encoder(z)\n",
    "        preds = self.regression_head(z)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            preds = preds.view(B*T, 2)\n",
    "            targets = targets.contiguous().view(B*T, 2).clamp(0, 1)\n",
    "            loss = F.l1_loss(preds, targets, reduction='none')\n",
    "            loss = loss[~loss.isnan()].mean()\n",
    "        return preds, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2dfbc56a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T14:50:44.383053Z",
     "iopub.status.busy": "2023-10-08T14:50:44.382575Z",
     "iopub.status.idle": "2023-10-08T14:50:46.252565Z",
     "shell.execute_reply": "2023-10-08T14:50:46.251425Z"
    },
    "papermill": {
     "duration": 1.874953,
     "end_time": "2023-10-08T14:50:46.254763",
     "exception": false,
     "start_time": "2023-10-08T14:50:44.379810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = RNA_Dataset(train_2A3, train_DMS), RNA_Dataset(val_2A3, val_DMS)\n",
    "trainsampler = GroupLengthBatchSampler(RandomSampler(train_dataset), batch_size, drop_last=True)\n",
    "valsampler = GroupLengthBatchSampler(RandomSampler(val_dataset), batch_size, drop_last=True)\n",
    "trainloader = DataLoader(train_dataset, batch_sampler=trainsampler, collate_fn=collate_fn)\n",
    "validloader = DataLoader(val_dataset, batch_sampler=valsampler, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a4e1fde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T14:50:46.261231Z",
     "iopub.status.busy": "2023-10-08T14:50:46.260600Z",
     "iopub.status.idle": "2023-10-08T14:50:50.064067Z",
     "shell.execute_reply": "2023-10-08T14:50:50.063105Z"
    },
    "papermill": {
     "duration": 3.808832,
     "end_time": "2023-10-08T14:50:50.066212",
     "exception": false,
     "start_time": "2023-10-08T14:50:46.257380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = torch.load(MODEL_PATH/\"best_model.pth\", map_location=device)\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f35839d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T14:50:50.073925Z",
     "iopub.status.busy": "2023-10-08T14:50:50.073614Z",
     "iopub.status.idle": "2023-10-08T14:50:50.079403Z",
     "shell.execute_reply": "2023-10-08T14:50:50.078608Z"
    },
    "papermill": {
     "duration": 0.011259,
     "end_time": "2023-10-08T14:50:50.081144",
     "exception": false,
     "start_time": "2023-10-08T14:50:50.069885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "train_steps = epochs * len(trainloader)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4381bd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T14:50:50.087368Z",
     "iopub.status.busy": "2023-10-08T14:50:50.086039Z",
     "iopub.status.idle": "2023-10-08T19:18:49.645690Z",
     "shell.execute_reply": "2023-10-08T19:18:49.644444Z"
    },
    "papermill": {
     "duration": 16079.564253,
     "end_time": "2023-10-08T19:18:49.647442",
     "exception": false,
     "start_time": "2023-10-08T14:50:50.083189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with 9,478,914 parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1274/1274 [08:40<00:00,  2.45it/s, Loss=0.136]\n",
      "100%|██████████| 141/141 [00:15<00:00,  9.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.13866277039051056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1274/1274 [08:38<00:00,  2.46it/s, Loss=0.135]\n",
      "100%|██████████| 141/141 [00:15<00:00,  8.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.13956549763679504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1274/1274 [08:39<00:00,  2.45it/s, Loss=0.135]\n",
      "100%|██████████| 141/141 [00:15<00:00,  9.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.13846315443515778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1274/1274 [08:40<00:00,  2.45it/s, Loss=0.135]\n",
      "100%|██████████| 141/141 [00:15<00:00,  9.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1387830227613449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1274/1274 [08:40<00:00,  2.45it/s, Loss=0.135]\n",
      "100%|██████████| 141/141 [00:15<00:00,  9.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.13940268754959106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1274/1274 [08:40<00:00,  2.45it/s, Loss=0.134]\n",
      "100%|██████████| 141/141 [00:15<00:00,  9.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.13798388838768005\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1274/1274 [08:39<00:00,  2.45it/s, Loss=0.134]\n",
      "100%|██████████| 141/141 [00:15<00:00,  9.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.13823768496513367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1274/1274 [08:40<00:00,  2.45it/s, Loss=0.133]\n",
      "100%|██████████| 141/141 [00:15<00:00,  9.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.13788586854934692\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1274/1274 [08:40<00:00,  2.45it/s, Loss=0.133]\n",
      "100%|██████████| 141/141 [00:15<00:00,  9.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1382211297750473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1274/1274 [08:40<00:00,  2.45it/s, Loss=0.132]\n",
      "100%|██████████| 141/141 [00:15<00:00,  9.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1378752589225769\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 1274/1274 [08:40<00:00,  2.45it/s, Loss=0.132]\n",
      "100%|██████████| 141/141 [00:15<00:00,  9.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1378674954175949\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 1274/1274 [08:41<00:00,  2.44it/s, Loss=0.132]\n",
      "100%|██████████| 141/141 [00:15<00:00,  9.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.13749952614307404\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 1274/1274 [08:41<00:00,  2.44it/s, Loss=0.132]\n",
      "100%|██████████| 141/141 [00:15<00:00,  9.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.13738518953323364\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 1274/1274 [08:41<00:00,  2.44it/s, Loss=0.131]\n",
      "100%|██████████| 141/141 [00:15<00:00,  8.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.13736163079738617\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 1274/1274 [08:40<00:00,  2.45it/s, Loss=0.131]\n",
      "100%|██████████| 141/141 [00:15<00:00,  9.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1375550925731659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 1274/1274 [08:40<00:00,  2.45it/s, Loss=0.131]\n",
      "100%|██████████| 141/141 [00:15<00:00,  9.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1374318152666092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 1274/1274 [08:39<00:00,  2.45it/s, Loss=0.13]\n",
      "100%|██████████| 141/141 [00:15<00:00,  9.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.13695305585861206\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 1274/1274 [08:39<00:00,  2.45it/s, Loss=0.13]\n",
      "100%|██████████| 141/141 [00:15<00:00,  8.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.13749806582927704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 1274/1274 [08:39<00:00,  2.45it/s, Loss=0.13]\n",
      "100%|██████████| 141/141 [00:15<00:00,  9.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1371692270040512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 1274/1274 [08:40<00:00,  2.45it/s, Loss=0.13]\n",
      "100%|██████████| 141/141 [00:15<00:00,  9.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.13695111870765686\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 1274/1274 [08:41<00:00,  2.44it/s, Loss=0.13]\n",
      "100%|██████████| 141/141 [00:15<00:00,  9.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1370006650686264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 1274/1274 [08:40<00:00,  2.45it/s, Loss=0.129]\n",
      "100%|██████████| 141/141 [00:15<00:00,  8.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.13686436414718628\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 1274/1274 [08:39<00:00,  2.45it/s, Loss=0.129]\n",
      "100%|██████████| 141/141 [00:15<00:00,  9.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.13669878244400024\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 1274/1274 [08:40<00:00,  2.45it/s, Loss=0.129]\n",
      "100%|██████████| 141/141 [00:15<00:00,  9.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.13671106100082397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 1274/1274 [08:40<00:00,  2.45it/s, Loss=0.129]\n",
      "100%|██████████| 141/141 [00:15<00:00,  9.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.13667283952236176\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 1274/1274 [08:41<00:00,  2.44it/s, Loss=0.129]\n",
      "100%|██████████| 141/141 [00:15<00:00,  9.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1368371546268463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 1274/1274 [08:40<00:00,  2.45it/s, Loss=0.129]\n",
      "100%|██████████| 141/141 [00:15<00:00,  8.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.13671113550662994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 1274/1274 [08:40<00:00,  2.45it/s, Loss=0.129]\n",
      "100%|██████████| 141/141 [00:15<00:00,  9.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.13677354156970978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 1274/1274 [08:39<00:00,  2.45it/s, Loss=0.129]\n",
      "100%|██████████| 141/141 [00:15<00:00,  9.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1366683393716812\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 1274/1274 [08:40<00:00,  2.45it/s, Loss=0.129]\n",
      "100%|██████████| 141/141 [00:15<00:00,  8.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.13668011128902435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def eval_loop():\n",
    "    model.eval()\n",
    "    losses = torch.zeros(len(validloader))\n",
    "    for i, (x, y) in tqdm(enumerate(validloader), total=len(validloader)):\n",
    "        _, loss = model(x.to(device), y.to(device))\n",
    "        losses[i] = loss.item()\n",
    "    model.train()\n",
    "    val_loss = losses.mean().item()\n",
    "    print(f\"Val Loss: {val_loss}\")\n",
    "    return val_loss\n",
    "            \n",
    "eval_distance = 500\n",
    "min_loss = 0.138\n",
    "n_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Training model with {n_params:,} parameters...\")\n",
    "loss_dict = {\"train_loss\": [], \"val_loss\": []}\n",
    "for epoch in range(epochs):\n",
    "    losses = torch.zeros(len(trainloader))\n",
    "    pbar = tqdm(enumerate(trainloader), total=len(trainloader))\n",
    "    pbar.set_description(f\"Epoch {epoch}\")\n",
    "    for i, (x, y) in pbar:\n",
    "        _, loss = model(x.to(device), y.to(device))\n",
    "        losses[i] = loss.item()\n",
    "        \n",
    "        if i >= eval_distance and i % eval_distance == 0:\n",
    "            train_loss = losses[i-eval_distance:i].mean().item()\n",
    "            pbar.set_postfix({\"Loss\":  train_loss})\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 3.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    val_loss = eval_loop()\n",
    "    loss_dict[\"train_loss\"].append(train_loss)\n",
    "    loss_dict[\"val_loss\"].append(val_loss)\n",
    "    if min_loss > val_loss:\n",
    "        print(\"Saving new best model...\")\n",
    "        min_loss = val_loss\n",
    "        torch.save(model, WORKING_PATH/\"best_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 16122.542578,
   "end_time": "2023-10-08T19:18:54.362814",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-08T14:50:11.820236",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
