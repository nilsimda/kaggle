{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport pathlib\nimport gc\nimport math\nimport random\n\nimport numpy as np\nimport pandas as pd\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\n\nfrom torch.utils.data import Dataset, DataLoader, BatchSampler, RandomSampler\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\nfrom torchmetrics.regression import MeanAbsoluteError","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-10-09T22:59:03.970563Z","iopub.execute_input":"2023-10-09T22:59:03.970922Z","iopub.status.idle":"2023-10-09T22:59:17.203306Z","shell.execute_reply.started":"2023-10-09T22:59:03.970899Z","shell.execute_reply":"2023-10-09T22:59:17.202387Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"INPUT_PATH = pathlib.Path('/kaggle/input/stanford-ribonanza-rna-folding-converted')\nMODEL_PATH = pathlib.Path('/kaggle/input/rna-folding-model/')\nWORKING_PATH = pathlib.Path('/kaggle/working/')\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"execution":{"iopub.status.busy":"2023-10-09T22:59:17.488256Z","iopub.execute_input":"2023-10-09T22:59:17.488601Z","iopub.status.idle":"2023-10-09T22:59:17.518025Z","shell.execute_reply.started":"2023-10-09T22:59:17.488574Z","shell.execute_reply":"2023-10-09T22:59:17.516866Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"full_df = pd.read_parquet(INPUT_PATH/\"train_data.parquet\")\n\ndf_2A3 = full_df[full_df.experiment_type =='2A3_MaP'].reset_index(drop=True)\ndf_DMS = full_df[full_df.experiment_type =='DMS_MaP'].reset_index(drop=True)\ntrain_2A3, val_2A3, train_DMS, val_DMS = train_test_split(df_2A3, df_DMS, test_size=0.05, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-10-09T22:59:22.494898Z","iopub.execute_input":"2023-10-09T22:59:22.495204Z","iopub.status.idle":"2023-10-09T22:59:42.987298Z","shell.execute_reply.started":"2023-10-09T22:59:22.495181Z","shell.execute_reply":"2023-10-09T22:59:42.986359Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class RNA_Dataset(Dataset):\n    def __init__(self, df_2A3, df_DMS): \n        self.seq_map = {'A':1, 'C':2, 'G':3, 'U':4}\n        self.seqs = df_2A3.sequence.values\n        self.react_2A3 = df_2A3[[c for c in df_2A3.columns if \\\n                                 'reactivity_0' in c]].values\n        self.react_DMS = df_DMS[[c for c in df_DMS.columns if \\\n                                 'reactivity_0' in c]].values\n        \n        react_error_2A3 = df_2A3[[c for c in df_2A3.columns if \\\n                                 'reactivity_error_0' in c]].values\n        react_error_DMS = df_DMS[[c for c in df_DMS.columns if \\\n                                 'reactivity_error_0' in c]].values\n        \n        self.react_2A3 = np.where((react_error_2A3 < 0.5), self.react_2A3, float(\"nan\"))\n        self.react_DMS = np.where((react_error_DMS < 0.5), self.react_DMS, float(\"nan\"))\n           \n    def __len__(self):\n        return len(self.seqs)\n        \n    def __getitem__(self, idx):\n        seq = self.seqs[idx]\n        seq_idx = torch.tensor([self.seq_map[s] for s in seq], dtype=torch.long)\n        labels = torch.tensor(np.stack([self.react_2A3[idx],\n                                           self.react_DMS[idx]], -1), dtype=torch.float32)\n        return seq_idx, labels\n    \n# Useful for sampling batches of similar lengths to minimize padding\nclass GroupLengthBatchSampler(BatchSampler):\n    def __iter__(self):\n        dataset = self.sampler.data_source\n        indices = [idx for idx in self.sampler]\n\n        step = 100 * self.batch_size\n        for i in range(0, len(dataset), step):\n            pool = indices[i:i+step]\n            pool = sorted(pool, key=lambda x: len(dataset[x][0]))\n            for j in range(0, len(pool), self.batch_size):\n                if j + self.batch_size > len(pool): # assume drop_last=True\n                    break\n                yield pool[j:j+self.batch_size]\n        \ndef collate_fn(data):\n    seq_idx, labels = zip(*data)\n    padded_seqs = nn.utils.rnn.pad_sequence(seq_idx, batch_first=True)\n    B, T = padded_seqs.shape\n    labels = torch.stack(labels)[:, :T, :]\n    return padded_seqs, labels","metadata":{"execution":{"iopub.status.busy":"2023-10-09T22:59:52.060391Z","iopub.execute_input":"2023-10-09T22:59:52.061058Z","iopub.status.idle":"2023-10-09T22:59:52.073855Z","shell.execute_reply.started":"2023-10-09T22:59:52.061028Z","shell.execute_reply":"2023-10-09T22:59:52.072891Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"vocab_size = 5 # the 4 bases + padding\nemb_dim = 256\nn_layers = 10\nn_heads =8\nbatch_size = 128\nitos = {0: \"<PAD>\", 1: \"A\", 2: \"C\", 3: \"G\", 4: \"U\"}\n\ndef precompute_freqs_cis(dim, end=500, theta=10000.0):\n    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n    t = torch.arange(end, device=freqs.device)  # type: ignore\n    freqs = torch.outer(t, freqs).float()  # type: ignore\n    freqs_cos = torch.cos(freqs)  # real part\n    freqs_sin = torch.sin(freqs)  # imaginary part\n    return freqs_cos, freqs_sin\n\ndef reshape_for_broadcast(freqs_cis, x):\n    ndim = x.ndim\n    assert 0 <= 1 < ndim\n    assert freqs_cis.shape == (x.shape[1], x.shape[-1])\n    shape = [d if i == 1 or i == ndim - 1 else 1 for i, d in enumerate(x.shape)]\n    return freqs_cis.view(shape)\n\ndef apply_rotary_emb(xq, xk, freqs_cos, freqs_sin):\n\n    # reshape xq and xk to match the complex representation\n    xq_r, xq_i = xq.float().reshape(xq.shape[:-1] + (-1, 2)).unbind(-1)\n    xk_r, xk_i = xk.float().reshape(xk.shape[:-1] + (-1, 2)).unbind(-1)\n\n    # reshape freqs_cos and freqs_sin for broadcasting\n    freqs_cos = reshape_for_broadcast(freqs_cos, xq_r)\n    freqs_sin = reshape_for_broadcast(freqs_sin, xq_r)\n\n    # apply rotation using real numbers\n    xq_out_r = xq_r * freqs_cos - xq_i * freqs_sin\n    xq_out_i = xq_r * freqs_sin + xq_i * freqs_cos\n    xk_out_r = xk_r * freqs_cos - xk_i * freqs_sin\n    xk_out_i = xk_r * freqs_sin + xk_i * freqs_cos\n\n    # flatten last two dimensions\n    xq_out = torch.stack([xq_out_r, xq_out_i], dim=-1).flatten(3)\n    xk_out = torch.stack([xk_out_r, xk_out_i], dim=-1).flatten(3)\n\n    return xq_out.type_as(xq), xk_out.type_as(xk)\n\nclass Attention(nn.Module):\n    def __init__(self, dropout=0.1):\n        super().__init__()\n        self.dropout = dropout\n        self.n_heads = n_heads\n        self.emb_dim = emb_dim\n        self.head_size = emb_dim // n_heads\n        self.c_attn = nn.Linear(emb_dim, 3*emb_dim, bias=False)\n        self.c_proj = nn.Linear(emb_dim, emb_dim, bias=False)\n        self.proj_dropout = nn.Dropout(dropout)\n        \n    def forward(self, x, freqs_cos, freqs_sin):\n        B, T, _ = x.shape\n        xq, xk, xv = self.c_attn(x).split(self.emb_dim, dim=2)\n        xq = xq.view(B, T, self.n_heads, self.head_size)\n        xk = xk.view(B, T, self.n_heads, self.head_size)\n        xv = xv.view(B, T, self.n_heads, self.head_size)\n        \n        # RoPE\n        xq, xk = apply_rotary_emb(xq, xk, freqs_cos, freqs_sin)\n        \n        xq = xq.transpose(1, 2)\n        xk = xk.transpose(1, 2)\n        xv = xv.transpose(1, 2)\n        \n        out = F.scaled_dot_product_attention(xq, xk, xv, dropout_p=self.dropout)\n        out = out.transpose(1, 2).contiguous().view(B, T, -1)\n        return self.proj_dropout(self.c_proj(out))\n    \nclass FeedForward(nn.Module):\n    def __init__(self, dropout=0.1):\n        super().__init__()\n        self.w1 = nn.Linear(emb_dim, 4*emb_dim, bias=False)\n        self.w2 = nn.Linear(4*emb_dim, emb_dim, bias=False)\n        self.w3 = nn.Linear(emb_dim, 4*emb_dim, bias=False)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        return self.dropout(self.w2(F.silu(self.w1(x)) * self.w3(x)))\n    \nclass EncoderBlock(nn.Module):\n    def __init__(self, dropout=0.1):\n        super().__init__()\n        self.attention = Attention()\n        self.feed_forward = FeedForward()\n        self.attention_norm = nn.LayerNorm(emb_dim)\n        self.ffn_norm = nn.LayerNorm(emb_dim)\n\n    def forward(self, x, freqs_cos, freqs_sin):\n        h = x + self.attention.forward(self.attention_norm(x), freqs_cos, freqs_sin)\n        out = h + self.feed_forward.forward(self.ffn_norm(h))\n        return out\n    \nclass RNA_Transformer(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.token_emb = nn.Embedding(vocab_size, emb_dim)\n        self.layers = nn.ModuleList()\n        for _ in range(n_layers):\n            self.layers.append(EncoderBlock())\n        self.regression_head = nn.Linear(emb_dim, 2)\n        freqs_cos, freqs_sin = precompute_freqs_cis(emb_dim//n_heads)\n        self.register_buffer(\"freqs_cos\", freqs_cos, persistent=False)\n        self.register_buffer(\"freqs_sin\", freqs_sin, persistent=False)\n        \n    def forward(self, x, targets=None):\n        B, T = x.shape\n        z = self.token_emb(x)\n        freqs_cos, freqs_sin = self.freqs_cos[:T], self.freqs_sin[:T]\n        \n        for layer in self.layers:\n            z = layer(z, freqs_cos, freqs_sin)\n        preds = self.regression_head(z)\n        \n        if targets is None:\n            loss = None\n        else:\n            preds = preds.view(B*T, 2)\n            targets = targets.contiguous().view(B*T, 2).clamp(0, 1)\n            loss = F.l1_loss(preds, targets, reduction='none')\n            loss = loss[~loss.isnan()].mean()\n        return preds, loss","metadata":{"execution":{"iopub.status.busy":"2023-10-09T22:59:55.513237Z","iopub.execute_input":"2023-10-09T22:59:55.513595Z","iopub.status.idle":"2023-10-09T22:59:55.535444Z","shell.execute_reply.started":"2023-10-09T22:59:55.513567Z","shell.execute_reply":"2023-10-09T22:59:55.534405Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_dataset, val_dataset = RNA_Dataset(train_2A3, train_DMS), RNA_Dataset(val_2A3, val_DMS)\ntrainsampler = GroupLengthBatchSampler(RandomSampler(train_dataset), batch_size, drop_last=True)\nvalsampler = GroupLengthBatchSampler(RandomSampler(val_dataset), batch_size, drop_last=True)\ntrainloader = DataLoader(train_dataset, batch_sampler=trainsampler, collate_fn=collate_fn)\nvalidloader = DataLoader(val_dataset, batch_sampler=valsampler, collate_fn=collate_fn)","metadata":{"execution":{"iopub.status.busy":"2023-10-09T22:59:57.763308Z","iopub.execute_input":"2023-10-09T22:59:57.763661Z","iopub.status.idle":"2023-10-09T23:00:04.260903Z","shell.execute_reply.started":"2023-10-09T22:59:57.763632Z","shell.execute_reply":"2023-10-09T23:00:04.259859Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"model = RNA_Transformer() #torch.load(MODEL_PATH/\"best_model.pth\", map_location=device)\nmodel.to(device);","metadata":{"execution":{"iopub.status.busy":"2023-10-09T23:00:05.552960Z","iopub.execute_input":"2023-10-09T23:00:05.553270Z","iopub.status.idle":"2023-10-09T23:00:10.617554Z","shell.execute_reply.started":"2023-10-09T23:00:05.553245Z","shell.execute_reply":"2023-10-09T23:00:10.616666Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"epochs = 30\noptimizer = torch.optim.AdamW(model.parameters(), lr=5e-4)\ntrain_steps = epochs * len(trainloader)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, train_steps)","metadata":{"execution":{"iopub.status.busy":"2023-10-09T23:00:12.517453Z","iopub.execute_input":"2023-10-09T23:00:12.518312Z","iopub.status.idle":"2023-10-09T23:00:12.523633Z","shell.execute_reply.started":"2023-10-09T23:00:12.518284Z","shell.execute_reply":"2023-10-09T23:00:12.522440Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\ndef eval_loop():\n    model.eval()\n    losses = torch.zeros(len(validloader))\n    for i, (x, labels) in tqdm(enumerate(validloader), total=len(validloader)):\n        _, loss = model(x.to(device), labels.to(device))\n        losses[i] = loss.item()\n    model.train()\n    val_loss = losses.mean().item()\n    print(f\"Val Loss: {val_loss}\")\n    return val_loss\n            \neval_distance = 500\nmin_loss = 0.2\nn_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint(f\"Training model with {n_params:,} parameters...\")\nloss_dict = {\"train_loss\": [], \"val_loss\": []}\nfor epoch in range(epochs):\n    losses = torch.zeros(len(trainloader))\n    pbar = tqdm(enumerate(trainloader), total=len(trainloader))\n    pbar.set_description(f\"Epoch {epoch}\")\n    for i, (x, y) in pbar:\n        _, loss= model(x.to(device), y.to(device))\n        losses[i] = loss.item()\n        \n        if i >= eval_distance and i % eval_distance == 0:\n            train_loss = losses[i-eval_distance:i].mean().item()\n            pbar.set_postfix({\"Loss\":  train_loss})\n        \n        optimizer.zero_grad()\n        loss.backward()\n        nn.utils.clip_grad_norm_(model.parameters(), 3.0)\n        optimizer.step()\n        scheduler.step()\n    eval_loop()\n    if min_loss > val_loss:\n        print(\"Saving new best model...\")\n        min_loss = val_loss\n        torch.save(model, WORKING_PATH/\"best_model.pth\")","metadata":{"execution":{"iopub.status.busy":"2023-10-09T23:00:14.825308Z","iopub.execute_input":"2023-10-09T23:00:14.825956Z","iopub.status.idle":"2023-10-09T23:00:44.983127Z","shell.execute_reply.started":"2023-10-09T23:00:14.825928Z","shell.execute_reply":"2023-10-09T23:00:44.980606Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Training model with 10,497,794 parameters...\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   1%|          | 64/6099 [00:28<45:24,  2.22it/s] \n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[9], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mset_postfix({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss\u001b[39m\u001b[38;5;124m\"\u001b[39m:  train_loss})\n\u001b[1;32m     30\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 31\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m nn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m3.0\u001b[39m)\n\u001b[1;32m     33\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"## TODOS\n* Mask Padding in Attention\n* Filter Sequences with only bad measurments from og data -> efficiency\n* Deal with Duplicate Sequences in og data\n* Improve Initialization of Tranformer","metadata":{}}]}