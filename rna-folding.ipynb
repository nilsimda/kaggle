{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4aeba51b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-10-08T19:29:20.090338Z",
     "iopub.status.busy": "2023-10-08T19:29:20.089927Z",
     "iopub.status.idle": "2023-10-08T19:29:25.147867Z",
     "shell.execute_reply": "2023-10-08T19:29:25.146922Z"
    },
    "papermill": {
     "duration": 5.066577,
     "end_time": "2023-10-08T19:29:25.150393",
     "exception": false,
     "start_time": "2023-10-08T19:29:20.083816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pathlib\n",
    "import gc\n",
    "import math\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, BatchSampler, RandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6d8e6b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T19:29:25.159065Z",
     "iopub.status.busy": "2023-10-08T19:29:25.157883Z",
     "iopub.status.idle": "2023-10-08T19:29:25.228741Z",
     "shell.execute_reply": "2023-10-08T19:29:25.227848Z"
    },
    "papermill": {
     "duration": 0.077297,
     "end_time": "2023-10-08T19:29:25.230868",
     "exception": false,
     "start_time": "2023-10-08T19:29:25.153571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "INPUT_PATH = pathlib.Path('/kaggle/input/stanford-ribonanza-rna-folding-converted')\n",
    "MODEL_PATH = pathlib.Path('/kaggle/input/rna-folding-model/')\n",
    "WORKING_PATH = pathlib.Path('/kaggle/working/')\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "517f37a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T19:29:25.237092Z",
     "iopub.status.busy": "2023-10-08T19:29:25.236814Z",
     "iopub.status.idle": "2023-10-08T19:29:45.579680Z",
     "shell.execute_reply": "2023-10-08T19:29:45.578567Z"
    },
    "papermill": {
     "duration": 20.348416,
     "end_time": "2023-10-08T19:29:45.581958",
     "exception": false,
     "start_time": "2023-10-08T19:29:25.233542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_df = pd.read_parquet(INPUT_PATH/\"train_data.parquet\")\n",
    "\n",
    "df_2A3 = full_df[full_df.experiment_type =='2A3_MaP'].reset_index(drop=True)\n",
    "df_DMS = full_df[full_df.experiment_type =='DMS_MaP'].reset_index(drop=True)\n",
    "train_2A3, val_2A3, train_DMS, val_DMS= train_test_split(df_2A3, df_DMS, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfb637a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T19:29:45.588624Z",
     "iopub.status.busy": "2023-10-08T19:29:45.588353Z",
     "iopub.status.idle": "2023-10-08T19:29:45.597911Z",
     "shell.execute_reply": "2023-10-08T19:29:45.596955Z"
    },
    "papermill": {
     "duration": 0.014977,
     "end_time": "2023-10-08T19:29:45.599597",
     "exception": false,
     "start_time": "2023-10-08T19:29:45.584620",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RNA_Dataset(Dataset):\n",
    "    def __init__(self, df_2A3, df_DMS):\n",
    "        # filter noisy data for now\n",
    "        predicate = (df_2A3.SN_filter.values > 0) & (df_DMS.SN_filter.values > 0)\n",
    "        df_2A3 = df_2A3[predicate].reset_index(drop=True)\n",
    "        df_DMS = df_DMS[predicate].reset_index(drop=True)\n",
    "        \n",
    "        self.seq_map = {'A':1, 'C':2, 'G':3, 'U':4}\n",
    "        self.seqs = df_2A3.sequence.values\n",
    "        self.react_2A3 = df_2A3[[c for c in df_2A3.columns if \\\n",
    "                                 'reactivity_0' in c]].values\n",
    "        self.react_DMS = df_DMS[[c for c in df_DMS.columns if \\\n",
    "                                 'reactivity_0' in c]].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.seqs)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seqs[idx]\n",
    "        seq_idx = torch.tensor([self.seq_map[s] for s in seq], dtype=torch.long)\n",
    "        labels = torch.tensor(np.stack([self.react_2A3[idx],\n",
    "                                           self.react_DMS[idx]], -1), dtype=torch.float32)\n",
    "        return seq_idx, labels\n",
    "    \n",
    "# Useful for sampling batches of similar lengths to minimize padding\n",
    "class GroupLengthBatchSampler(BatchSampler):\n",
    "    def __iter__(self):\n",
    "        dataset = self.sampler.data_source\n",
    "        indices = [idx for idx in self.sampler]\n",
    "\n",
    "        step = 100 * self.batch_size\n",
    "        for i in range(0, len(dataset), step):\n",
    "            pool = indices[i:i+step]\n",
    "            pool = sorted(pool, key=lambda x: len(dataset[x][0]))\n",
    "            for j in range(0, len(pool), self.batch_size):\n",
    "                if j + self.batch_size > len(pool): # assume drop_last=True\n",
    "                    break\n",
    "                yield pool[j:j+self.batch_size]\n",
    "        \n",
    "def collate_fn(data):\n",
    "    seq_idx, labels = zip(*data)\n",
    "    padded_seqs = nn.utils.rnn.pad_sequence(seq_idx, batch_first=True)\n",
    "    B, T = padded_seqs.shape\n",
    "    labels = torch.stack(labels)[:, :T, :]\n",
    "    return padded_seqs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f681fe8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T19:29:45.605723Z",
     "iopub.status.busy": "2023-10-08T19:29:45.605467Z",
     "iopub.status.idle": "2023-10-08T19:29:45.626199Z",
     "shell.execute_reply": "2023-10-08T19:29:45.625390Z"
    },
    "papermill": {
     "duration": 0.026017,
     "end_time": "2023-10-08T19:29:45.627928",
     "exception": false,
     "start_time": "2023-10-08T19:29:45.601911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab_size = 5 # the 4 bases + padding\n",
    "emb_dim = 256\n",
    "n_layers = 12\n",
    "n_heads =8\n",
    "batch_size = 128\n",
    "itos = {0: \"<PAD>\", 1: \"A\", 2: \"C\", 3: \"G\", 4: \"U\"}\n",
    "\n",
    "def precompute_freqs_cis(dim, end=500, theta=10000.0):\n",
    "    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n",
    "    t = torch.arange(end, device=freqs.device)  # type: ignore\n",
    "    freqs = torch.outer(t, freqs).float()  # type: ignore\n",
    "    freqs_cos = torch.cos(freqs)  # real part\n",
    "    freqs_sin = torch.sin(freqs)  # imaginary part\n",
    "    return freqs_cos, freqs_sin\n",
    "\n",
    "def reshape_for_broadcast(freqs_cis, x):\n",
    "    ndim = x.ndim\n",
    "    assert 0 <= 1 < ndim\n",
    "    assert freqs_cis.shape == (x.shape[1], x.shape[-1])\n",
    "    shape = [d if i == 1 or i == ndim - 1 else 1 for i, d in enumerate(x.shape)]\n",
    "    return freqs_cis.view(shape)\n",
    "\n",
    "def apply_rotary_emb(xq, xk, freqs_cos, freqs_sin):\n",
    "\n",
    "    # reshape xq and xk to match the complex representation\n",
    "    xq_r, xq_i = xq.float().reshape(xq.shape[:-1] + (-1, 2)).unbind(-1)\n",
    "    xk_r, xk_i = xk.float().reshape(xk.shape[:-1] + (-1, 2)).unbind(-1)\n",
    "\n",
    "    # reshape freqs_cos and freqs_sin for broadcasting\n",
    "    freqs_cos = reshape_for_broadcast(freqs_cos, xq_r)\n",
    "    freqs_sin = reshape_for_broadcast(freqs_sin, xq_r)\n",
    "\n",
    "    # apply rotation using real numbers\n",
    "    xq_out_r = xq_r * freqs_cos - xq_i * freqs_sin\n",
    "    xq_out_i = xq_r * freqs_sin + xq_i * freqs_cos\n",
    "    xk_out_r = xk_r * freqs_cos - xk_i * freqs_sin\n",
    "    xk_out_i = xk_r * freqs_sin + xk_i * freqs_cos\n",
    "\n",
    "    # flatten last two dimensions\n",
    "    xq_out = torch.stack([xq_out_r, xq_out_i], dim=-1).flatten(3)\n",
    "    xk_out = torch.stack([xk_out_r, xk_out_i], dim=-1).flatten(3)\n",
    "\n",
    "    return xq_out.type_as(xq), xk_out.type_as(xk)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = dropout\n",
    "        self.n_heads = n_heads\n",
    "        self.emb_dim = emb_dim\n",
    "        self.head_size = emb_dim // n_heads\n",
    "        self.c_attn = nn.Linear(emb_dim, 3*emb_dim, bias=False)\n",
    "        self.c_proj = nn.Linear(emb_dim, emb_dim, bias=False)\n",
    "        self.proj_dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, freqs_cos, freqs_sin):\n",
    "        B, T, _ = x.shape\n",
    "        xq, xk, xv = self.c_attn(x).split(self.emb_dim, dim=2)\n",
    "        xq = xq.view(B, T, self.n_heads, self.head_size)\n",
    "        xk = xk.view(B, T, self.n_heads, self.head_size)\n",
    "        xv = xv.view(B, T, self.n_heads, self.head_size)\n",
    "        \n",
    "        # RoPE\n",
    "        xq, xk = apply_rotary_emb(xq, xk, freqs_cos, freqs_sin)\n",
    "        \n",
    "        xq = xq.transpose(1, 2)\n",
    "        xk = xk.transpose(1, 2)\n",
    "        xv = xv.transpose(1, 2)\n",
    "        \n",
    "        out = F.scaled_dot_product_attention(xq, xk, xv, dropout_p=self.dropout)\n",
    "        out = out.transpose(1, 2).contiguous().view(B, T, -1)\n",
    "        return self.proj_dropout(self.c_proj(out))\n",
    "    \n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.w1 = nn.Linear(emb_dim, 4*emb_dim, bias=False)\n",
    "        self.w2 = nn.Linear(4*emb_dim, emb_dim, bias=False)\n",
    "        self.w3 = nn.Linear(emb_dim, 4*emb_dim, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.dropout(self.w2(F.silu(self.w1(x)) * self.w3(x)))\n",
    "    \n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.attention = Attention()\n",
    "        self.feed_forward = FeedForward()\n",
    "        self.attention_norm = nn.LayerNorm(emb_dim)\n",
    "        self.ffn_norm = nn.LayerNorm(emb_dim)\n",
    "\n",
    "    def forward(self, x, freqs_cos, freqs_sin):\n",
    "        h = x + self.attention.forward(self.attention_norm(x), freqs_cos, freqs_sin)\n",
    "        out = h + self.feed_forward.forward(self.ffn_norm(h))\n",
    "        return out\n",
    "    \n",
    "class RNA_Transformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.layers = nn.ModuleList()\n",
    "        for _ in range(n_layers):\n",
    "            self.layers.append(EncoderBlock())\n",
    "        self.regression_head = nn.Linear(emb_dim, 2)\n",
    "        freqs_cos, freqs_sin = precompute_freqs_cis(emb_dim//n_heads)\n",
    "        self.register_buffer(\"freqs_cos\", freqs_cos, persistent=False)\n",
    "        self.register_buffer(\"freqs_sin\", freqs_sin, persistent=False)\n",
    "        \n",
    "    def forward(self, x, targets=None):\n",
    "        B, T = x.shape\n",
    "        z = self.token_emb(x)\n",
    "        freqs_cos, freqs_sin = self.freqs_cos[:T], self.freqs_sin[:T]\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            z = layer(z, freqs_cos, freqs_sin)\n",
    "        preds = self.regression_head(z)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            preds = preds.view(B*T, 2)\n",
    "            targets = targets.contiguous().view(B*T, 2).clamp(0, 1)\n",
    "            loss = F.l1_loss(preds, targets, reduction='none')\n",
    "            loss = loss[~loss.isnan()].mean()\n",
    "        return preds, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc88ce22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T19:29:45.634203Z",
     "iopub.status.busy": "2023-10-08T19:29:45.633596Z",
     "iopub.status.idle": "2023-10-08T19:29:47.024385Z",
     "shell.execute_reply": "2023-10-08T19:29:47.023320Z"
    },
    "papermill": {
     "duration": 1.396658,
     "end_time": "2023-10-08T19:29:47.026822",
     "exception": false,
     "start_time": "2023-10-08T19:29:45.630164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = RNA_Dataset(train_2A3, train_DMS), RNA_Dataset(val_2A3, val_DMS)\n",
    "trainsampler = GroupLengthBatchSampler(RandomSampler(train_dataset), batch_size, drop_last=True)\n",
    "valsampler = GroupLengthBatchSampler(RandomSampler(val_dataset), batch_size, drop_last=True)\n",
    "trainloader = DataLoader(train_dataset, batch_sampler=trainsampler, collate_fn=collate_fn)\n",
    "validloader = DataLoader(val_dataset, batch_sampler=valsampler, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2036d3fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T19:29:47.033654Z",
     "iopub.status.busy": "2023-10-08T19:29:47.033348Z",
     "iopub.status.idle": "2023-10-08T19:29:50.457189Z",
     "shell.execute_reply": "2023-10-08T19:29:50.456202Z"
    },
    "papermill": {
     "duration": 3.43005,
     "end_time": "2023-10-08T19:29:50.459804",
     "exception": false,
     "start_time": "2023-10-08T19:29:47.029754",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = RNA_Transformer() #torch.load(MODEL_PATH/\"best_model.pth\", map_location=device)\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c667a010",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T19:29:50.466062Z",
     "iopub.status.busy": "2023-10-08T19:29:50.465748Z",
     "iopub.status.idle": "2023-10-08T19:29:50.470987Z",
     "shell.execute_reply": "2023-10-08T19:29:50.469967Z"
    },
    "papermill": {
     "duration": 0.010186,
     "end_time": "2023-10-08T19:29:50.472622",
     "exception": false,
     "start_time": "2023-10-08T19:29:50.462436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4)\n",
    "train_steps = epochs * len(trainloader)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3dcb67e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T19:29:50.480605Z",
     "iopub.status.busy": "2023-10-08T19:29:50.480085Z",
     "iopub.status.idle": "2023-10-09T04:07:31.729008Z",
     "shell.execute_reply": "2023-10-09T04:07:31.727883Z"
    },
    "papermill": {
     "duration": 31061.255908,
     "end_time": "2023-10-09T04:07:31.730766",
     "exception": false,
     "start_time": "2023-10-08T19:29:50.474858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with 12,596,994 parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1274/1274 [10:00<00:00,  2.12it/s, Loss=0.205]\n",
      "100%|██████████| 141/141 [00:23<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.19259080290794373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1274/1274 [09:57<00:00,  2.13it/s, Loss=0.186]\n",
      "100%|██████████| 141/141 [00:23<00:00,  6.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1819210648536682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1274/1274 [09:56<00:00,  2.13it/s, Loss=0.178]\n",
      "100%|██████████| 141/141 [00:23<00:00,  6.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1742209792137146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1274/1274 [09:57<00:00,  2.13it/s, Loss=0.172]\n",
      "100%|██████████| 141/141 [00:23<00:00,  6.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.17077411711215973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1274/1274 [09:57<00:00,  2.13it/s, Loss=0.168]\n",
      "100%|██████████| 141/141 [00:23<00:00,  6.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.16777914762496948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1274/1274 [09:57<00:00,  2.13it/s, Loss=0.162]\n",
      "100%|██████████| 141/141 [00:23<00:00,  6.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.16105113923549652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1274/1274 [09:57<00:00,  2.13it/s, Loss=0.158]\n",
      "100%|██████████| 141/141 [00:23<00:00,  6.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.15783005952835083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1274/1274 [09:57<00:00,  2.13it/s, Loss=0.155]\n",
      "100%|██████████| 141/141 [00:23<00:00,  6.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.15639294683933258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1274/1274 [09:58<00:00,  2.13it/s, Loss=0.153]\n",
      "100%|██████████| 141/141 [00:23<00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1525498777627945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1274/1274 [09:57<00:00,  2.13it/s, Loss=0.15]\n",
      "100%|██████████| 141/141 [00:23<00:00,  6.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.15135781466960907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 1274/1274 [09:57<00:00,  2.13it/s, Loss=0.148]\n",
      "100%|██████████| 141/141 [00:22<00:00,  6.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1505119651556015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 1274/1274 [09:57<00:00,  2.13it/s, Loss=0.147]\n",
      "100%|██████████| 141/141 [00:23<00:00,  6.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.14868344366550446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 1274/1274 [09:58<00:00,  2.13it/s, Loss=0.145]\n",
      "100%|██████████| 141/141 [00:23<00:00,  6.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1477375626564026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 1274/1274 [09:57<00:00,  2.13it/s, Loss=0.143]\n",
      "100%|██████████| 141/141 [00:23<00:00,  6.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.14668205380439758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 1274/1274 [09:56<00:00,  2.14it/s, Loss=0.142]\n",
      "100%|██████████| 141/141 [00:23<00:00,  6.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1458306759595871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 1274/1274 [09:56<00:00,  2.14it/s, Loss=0.141]\n",
      "100%|██████████| 141/141 [00:23<00:00,  6.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.14558008313179016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 1274/1274 [09:57<00:00,  2.13it/s, Loss=0.139]\n",
      "100%|██████████| 141/141 [00:23<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.14430512487888336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 1274/1274 [09:57<00:00,  2.13it/s, Loss=0.138]\n",
      "100%|██████████| 141/141 [00:23<00:00,  6.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.14443637430667877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 1274/1274 [09:56<00:00,  2.13it/s, Loss=0.138]\n",
      "100%|██████████| 141/141 [00:23<00:00,  6.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.14434711635112762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 1274/1274 [09:57<00:00,  2.13it/s, Loss=0.136]\n",
      "100%|██████████| 141/141 [00:23<00:00,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.14332620799541473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 1274/1274 [09:57<00:00,  2.13it/s, Loss=0.135]\n",
      "100%|██████████| 141/141 [00:22<00:00,  6.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1433216631412506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 1274/1274 [09:55<00:00,  2.14it/s, Loss=0.135]\n",
      "100%|██████████| 141/141 [00:23<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1424853652715683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 1274/1274 [09:56<00:00,  2.14it/s, Loss=0.133]\n",
      "100%|██████████| 141/141 [00:23<00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.14218170940876007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 1274/1274 [09:56<00:00,  2.14it/s, Loss=0.133]\n",
      "100%|██████████| 141/141 [00:23<00:00,  6.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.14201928675174713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 1274/1274 [09:58<00:00,  2.13it/s, Loss=0.132]\n",
      "100%|██████████| 141/141 [00:23<00:00,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1414187103509903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 1274/1274 [09:56<00:00,  2.13it/s, Loss=0.131]\n",
      "100%|██████████| 141/141 [00:23<00:00,  6.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.14124636352062225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 1274/1274 [09:56<00:00,  2.13it/s, Loss=0.131]\n",
      "100%|██████████| 141/141 [00:22<00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1413615494966507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 1274/1274 [09:56<00:00,  2.14it/s, Loss=0.13]\n",
      "100%|██████████| 141/141 [00:23<00:00,  6.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.14097827672958374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 1274/1274 [09:56<00:00,  2.13it/s, Loss=0.129]\n",
      "100%|██████████| 141/141 [00:23<00:00,  6.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.14072704315185547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 1274/1274 [09:58<00:00,  2.13it/s, Loss=0.128]\n",
      "100%|██████████| 141/141 [00:23<00:00,  6.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.14065854251384735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 1274/1274 [09:56<00:00,  2.14it/s, Loss=0.128]\n",
      "100%|██████████| 141/141 [00:22<00:00,  6.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.13967639207839966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 1274/1274 [09:56<00:00,  2.14it/s, Loss=0.127]\n",
      "100%|██████████| 141/141 [00:23<00:00,  6.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1400841325521469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 1274/1274 [09:57<00:00,  2.13it/s, Loss=0.126]\n",
      "100%|██████████| 141/141 [00:23<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.14003320038318634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 1274/1274 [09:57<00:00,  2.13it/s, Loss=0.126]\n",
      "100%|██████████| 141/141 [00:22<00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.13949140906333923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 1274/1274 [09:56<00:00,  2.13it/s, Loss=0.125]\n",
      "100%|██████████| 141/141 [00:23<00:00,  6.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.13947300612926483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 1274/1274 [09:56<00:00,  2.13it/s, Loss=0.126]\n",
      "100%|██████████| 141/141 [00:23<00:00,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.13946256041526794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 1274/1274 [10:00<00:00,  2.12it/s, Loss=0.125]\n",
      "100%|██████████| 141/141 [00:23<00:00,  6.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.13932353258132935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 1274/1274 [10:00<00:00,  2.12it/s, Loss=0.124]\n",
      "100%|██████████| 141/141 [00:23<00:00,  6.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.13929443061351776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 1274/1274 [09:59<00:00,  2.12it/s, Loss=0.124]\n",
      "100%|██████████| 141/141 [00:23<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.13916917145252228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 1274/1274 [09:59<00:00,  2.13it/s, Loss=0.123]\n",
      "100%|██████████| 141/141 [00:23<00:00,  6.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.13888515532016754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 1274/1274 [09:59<00:00,  2.13it/s, Loss=0.123]\n",
      "100%|██████████| 141/141 [00:23<00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.138809934258461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 1274/1274 [10:02<00:00,  2.12it/s, Loss=0.122]\n",
      "100%|██████████| 141/141 [00:23<00:00,  6.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.13877438008785248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 1274/1274 [09:58<00:00,  2.13it/s, Loss=0.122]\n",
      "100%|██████████| 141/141 [00:23<00:00,  6.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1387282758951187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 1274/1274 [09:59<00:00,  2.13it/s, Loss=0.122]\n",
      "100%|██████████| 141/141 [00:23<00:00,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.13873112201690674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 1274/1274 [09:59<00:00,  2.12it/s, Loss=0.122]\n",
      "100%|██████████| 141/141 [00:23<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.13879764080047607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 1274/1274 [09:58<00:00,  2.13it/s, Loss=0.122]\n",
      "100%|██████████| 141/141 [00:23<00:00,  6.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1386171281337738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 1274/1274 [09:59<00:00,  2.12it/s, Loss=0.122]\n",
      "100%|██████████| 141/141 [00:23<00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.13850858807563782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 1274/1274 [10:00<00:00,  2.12it/s, Loss=0.122]\n",
      "100%|██████████| 141/141 [00:23<00:00,  6.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.13863098621368408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 1274/1274 [09:59<00:00,  2.12it/s, Loss=0.121]\n",
      "100%|██████████| 141/141 [00:23<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.13861501216888428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 1274/1274 [10:00<00:00,  2.12it/s, Loss=0.121]\n",
      "100%|██████████| 141/141 [00:23<00:00,  5.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1385551393032074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def eval_loop():\n",
    "    model.eval()\n",
    "    losses = torch.zeros(len(validloader))\n",
    "    for i, (x, y) in tqdm(enumerate(validloader), total=len(validloader)):\n",
    "        _, loss = model(x.to(device), y.to(device))\n",
    "        losses[i] = loss.item()\n",
    "    model.train()\n",
    "    val_loss = losses.mean().item()\n",
    "    print(f\"Val Loss: {val_loss}\")\n",
    "    return val_loss\n",
    "            \n",
    "eval_distance = 500\n",
    "min_loss = 0.138\n",
    "n_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Training model with {n_params:,} parameters...\")\n",
    "loss_dict = {\"train_loss\": [], \"val_loss\": []}\n",
    "for epoch in range(epochs):\n",
    "    losses = torch.zeros(len(trainloader))\n",
    "    pbar = tqdm(enumerate(trainloader), total=len(trainloader))\n",
    "    pbar.set_description(f\"Epoch {epoch}\")\n",
    "    for i, (x, y) in pbar:\n",
    "        _, loss = model(x.to(device), y.to(device))\n",
    "        losses[i] = loss.item()\n",
    "        \n",
    "        if i >= eval_distance and i % eval_distance == 0:\n",
    "            train_loss = losses[i-eval_distance:i].mean().item()\n",
    "            pbar.set_postfix({\"Loss\":  train_loss})\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 3.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    val_loss = eval_loop()\n",
    "    loss_dict[\"train_loss\"].append(train_loss)\n",
    "    loss_dict[\"val_loss\"].append(val_loss)\n",
    "    if min_loss > val_loss:\n",
    "        print(\"Saving new best model...\")\n",
    "        min_loss = val_loss\n",
    "        torch.save(model, WORKING_PATH/\"best_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89371e2",
   "metadata": {
    "papermill": {
     "duration": 3.305391,
     "end_time": "2023-10-09T04:07:38.429876",
     "exception": false,
     "start_time": "2023-10-09T04:07:35.124485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 31107.390823,
   "end_time": "2023-10-09T04:07:44.455979",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-08T19:29:17.065156",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
