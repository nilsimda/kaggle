{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cc5ed80",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-10-13T13:14:02.503524Z",
     "iopub.status.busy": "2023-10-13T13:14:02.503213Z",
     "iopub.status.idle": "2023-10-13T13:14:17.504502Z",
     "shell.execute_reply": "2023-10-13T13:14:17.503533Z"
    },
    "papermill": {
     "duration": 15.008014,
     "end_time": "2023-10-13T13:14:17.506667",
     "exception": false,
     "start_time": "2023-10-13T13:14:02.498653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pathlib\n",
    "import gc\n",
    "import math\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, BatchSampler, RandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from torchmetrics.regression import MeanAbsoluteError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "602fbff0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T13:14:17.513771Z",
     "iopub.status.busy": "2023-10-13T13:14:17.512851Z",
     "iopub.status.idle": "2023-10-13T13:14:17.575652Z",
     "shell.execute_reply": "2023-10-13T13:14:17.574704Z"
    },
    "papermill": {
     "duration": 0.068311,
     "end_time": "2023-10-13T13:14:17.577798",
     "exception": false,
     "start_time": "2023-10-13T13:14:17.509487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "INPUT_PATH = pathlib.Path('/kaggle/input/stanford-ribonanza-rna-folding-converted')\n",
    "MODEL_PATH = pathlib.Path('/kaggle/input/rna-folding-model/')\n",
    "WORKING_PATH = pathlib.Path('/kaggle/working/')\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "649b66f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T13:14:17.584377Z",
     "iopub.status.busy": "2023-10-13T13:14:17.584084Z",
     "iopub.status.idle": "2023-10-13T13:14:38.221602Z",
     "shell.execute_reply": "2023-10-13T13:14:38.220694Z"
    },
    "papermill": {
     "duration": 20.643211,
     "end_time": "2023-10-13T13:14:38.223749",
     "exception": false,
     "start_time": "2023-10-13T13:14:17.580538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Train Sequences: 330_747\n",
      "Number of Validation Sequences: 17_408\n"
     ]
    }
   ],
   "source": [
    "full_df = pd.read_parquet(INPUT_PATH/\"train_data.parquet\")\n",
    "\n",
    "# split by experiment type\n",
    "df_2A3 = full_df[full_df.experiment_type =='2A3_MaP'].reset_index(drop=True)\n",
    "df_DMS = full_df[full_df.experiment_type =='DMS_MaP'].reset_index(drop=True)\n",
    "\n",
    "# keep only sequences that have at least min_samples measurements with error < max_error for at least one of the experiments\n",
    "max_error = 0.5\n",
    "min_samples = 10\n",
    "m1 = ((df_2A3.loc[:, \"reactivity_error_0001\":\"reactivity_error_0206\"] < max_error).sum(axis=1) >= min_samples)\n",
    "m2 = ((df_DMS.loc[:, \"reactivity_error_0001\":\"reactivity_error_0206\"] < max_error).sum(axis=1) >= min_samples)\n",
    "df_2A3 = df_2A3[m1 | m2].reset_index(drop=True)\n",
    "df_DMS = df_DMS[m1 | m2].reset_index(drop=True)\n",
    "\n",
    "# train val split\n",
    "train_2A3, val_2A3, train_DMS, val_DMS = train_test_split(df_2A3, df_DMS, test_size=0.05, random_state=42)\n",
    "\n",
    "print(f\"Number of Train Sequences: {len(train_DMS):_}\")\n",
    "print(f\"Number of Validation Sequences: {len(val_DMS):_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "970251ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T13:14:38.230289Z",
     "iopub.status.busy": "2023-10-13T13:14:38.229788Z",
     "iopub.status.idle": "2023-10-13T13:14:38.240165Z",
     "shell.execute_reply": "2023-10-13T13:14:38.239188Z"
    },
    "papermill": {
     "duration": 0.015503,
     "end_time": "2023-10-13T13:14:38.241845",
     "exception": false,
     "start_time": "2023-10-13T13:14:38.226342",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RNA_Dataset(Dataset):\n",
    "    def __init__(self, df_2A3, df_DMS): \n",
    "        self.seq_map = {'A':1, 'C':2, 'G':3, 'U':4}\n",
    "        self.seqs = df_2A3.sequence.values\n",
    "        self.react_2A3 = df_2A3[[c for c in df_2A3.columns if \\\n",
    "                                 'reactivity_0' in c]].values\n",
    "        self.react_DMS = df_DMS[[c for c in df_DMS.columns if \\\n",
    "                                 'reactivity_0' in c]].values\n",
    "        \n",
    "        react_error_2A3 = df_2A3[[c for c in df_2A3.columns if \\\n",
    "                                 'reactivity_error_0' in c]].values\n",
    "        react_error_DMS = df_DMS[[c for c in df_DMS.columns if \\\n",
    "                                 'reactivity_error_0' in c]].values\n",
    "        \n",
    "        self.react_2A3 = np.where((react_error_2A3 < max_error), self.react_2A3, float(\"nan\"))\n",
    "        self.react_DMS = np.where((react_error_DMS < max_error), self.react_DMS, float(\"nan\"))\n",
    "           \n",
    "    def __len__(self):\n",
    "        return len(self.seqs)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seqs[idx]\n",
    "        seq_idx = torch.tensor([self.seq_map[s] for s in seq], dtype=torch.long)\n",
    "        labels = torch.tensor(np.stack([self.react_2A3[idx],\n",
    "                                           self.react_DMS[idx]], -1), dtype=torch.float32)\n",
    "        return seq_idx, labels\n",
    "    \n",
    "# Useful for sampling batches of similar lengths to minimize padding\n",
    "class GroupLengthBatchSampler(BatchSampler):\n",
    "    def __iter__(self):\n",
    "        dataset = self.sampler.data_source\n",
    "        indices = [idx for idx in self.sampler]\n",
    "\n",
    "        step = 100 * self.batch_size\n",
    "        for i in range(0, len(dataset), step):\n",
    "            pool = indices[i:i+step]\n",
    "            pool = sorted(pool, key=lambda x: len(dataset[x][0]))\n",
    "            for j in range(0, len(pool), self.batch_size):\n",
    "                if j + self.batch_size > len(pool): # assume drop_last=True\n",
    "                    break\n",
    "                yield pool[j:j+self.batch_size]\n",
    "        \n",
    "def collate_fn(data):\n",
    "    seq_idx, labels = zip(*data)\n",
    "    padded_seqs = nn.utils.rnn.pad_sequence(seq_idx, batch_first=True)\n",
    "    B, T = padded_seqs.shape\n",
    "    labels = torch.stack(labels)[:, :T, :]\n",
    "    return padded_seqs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "331d6910",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T13:14:38.248034Z",
     "iopub.status.busy": "2023-10-13T13:14:38.247764Z",
     "iopub.status.idle": "2023-10-13T13:14:38.269269Z",
     "shell.execute_reply": "2023-10-13T13:14:38.268537Z"
    },
    "papermill": {
     "duration": 0.026652,
     "end_time": "2023-10-13T13:14:38.270915",
     "exception": false,
     "start_time": "2023-10-13T13:14:38.244263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab_size = 5 # the 4 bases + padding\n",
    "emb_dim = 256\n",
    "n_layers = 12\n",
    "n_heads = 8\n",
    "batch_size = 128\n",
    "itos = {0: \"<PAD>\", 1: \"A\", 2: \"C\", 3: \"G\", 4: \"U\"}\n",
    "\n",
    "def precompute_freqs_cis(dim, end=500, theta=10000.0):\n",
    "    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n",
    "    t = torch.arange(end, device=freqs.device)  # type: ignore\n",
    "    freqs = torch.outer(t, freqs).float()  # type: ignore\n",
    "    freqs_cos = torch.cos(freqs)  # real part\n",
    "    freqs_sin = torch.sin(freqs)  # imaginary part\n",
    "    return freqs_cos, freqs_sin\n",
    "\n",
    "def reshape_for_broadcast(freqs_cis, x):\n",
    "    ndim = x.ndim\n",
    "    assert 0 <= 1 < ndim\n",
    "    assert freqs_cis.shape == (x.shape[1], x.shape[-1])\n",
    "    shape = [d if i == 1 or i == ndim - 1 else 1 for i, d in enumerate(x.shape)]\n",
    "    return freqs_cis.view(shape)\n",
    "\n",
    "def apply_rotary_emb(xq, xk, freqs_cos, freqs_sin):\n",
    "\n",
    "    # reshape xq and xk to match the complex representation\n",
    "    xq_r, xq_i = xq.float().reshape(xq.shape[:-1] + (-1, 2)).unbind(-1)\n",
    "    xk_r, xk_i = xk.float().reshape(xk.shape[:-1] + (-1, 2)).unbind(-1)\n",
    "\n",
    "    # reshape freqs_cos and freqs_sin for broadcasting\n",
    "    freqs_cos = reshape_for_broadcast(freqs_cos, xq_r)\n",
    "    freqs_sin = reshape_for_broadcast(freqs_sin, xq_r)\n",
    "\n",
    "    # apply rotation using real numbers\n",
    "    xq_out_r = xq_r * freqs_cos - xq_i * freqs_sin\n",
    "    xq_out_i = xq_r * freqs_sin + xq_i * freqs_cos\n",
    "    xk_out_r = xk_r * freqs_cos - xk_i * freqs_sin\n",
    "    xk_out_i = xk_r * freqs_sin + xk_i * freqs_cos\n",
    "\n",
    "    # flatten last two dimensions\n",
    "    xq_out = torch.stack([xq_out_r, xq_out_i], dim=-1).flatten(3)\n",
    "    xk_out = torch.stack([xk_out_r, xk_out_i], dim=-1).flatten(3)\n",
    "\n",
    "    return xq_out.type_as(xq), xk_out.type_as(xk)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = dropout\n",
    "        self.n_heads = n_heads\n",
    "        self.emb_dim = emb_dim\n",
    "        self.head_size = emb_dim // n_heads\n",
    "        self.c_attn = nn.Linear(emb_dim, 3*emb_dim, bias=False)\n",
    "        self.c_proj = nn.Linear(emb_dim, emb_dim, bias=False)\n",
    "        self.proj_dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, freqs_cos, freqs_sin):\n",
    "        B, T, _ = x.shape\n",
    "        xq, xk, xv = self.c_attn(x).split(self.emb_dim, dim=2)\n",
    "        xq = xq.view(B, T, self.n_heads, self.head_size)\n",
    "        xk = xk.view(B, T, self.n_heads, self.head_size)\n",
    "        xv = xv.view(B, T, self.n_heads, self.head_size)\n",
    "        \n",
    "        # RoPE\n",
    "        xq, xk = apply_rotary_emb(xq, xk, freqs_cos, freqs_sin)\n",
    "        \n",
    "        xq = xq.transpose(1, 2)\n",
    "        xk = xk.transpose(1, 2)\n",
    "        xv = xv.transpose(1, 2)\n",
    "        \n",
    "        out = F.scaled_dot_product_attention(xq, xk, xv, dropout_p=self.dropout)\n",
    "        out = out.transpose(1, 2).contiguous().view(B, T, -1)\n",
    "        return self.proj_dropout(self.c_proj(out))\n",
    "    \n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.w1 = nn.Linear(emb_dim, 4*emb_dim, bias=False)\n",
    "        self.w2 = nn.Linear(4*emb_dim, emb_dim, bias=False)\n",
    "        self.w3 = nn.Linear(emb_dim, 4*emb_dim, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.dropout(self.w2(F.silu(self.w1(x)) * self.w3(x)))\n",
    "    \n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.attention = Attention()\n",
    "        self.feed_forward = FeedForward()\n",
    "        self.attention_norm = nn.LayerNorm(emb_dim)\n",
    "        self.ffn_norm = nn.LayerNorm(emb_dim)\n",
    "\n",
    "    def forward(self, x, freqs_cos, freqs_sin):\n",
    "        h = x + self.attention.forward(self.attention_norm(x), freqs_cos, freqs_sin)\n",
    "        out = h + self.feed_forward.forward(self.ffn_norm(h))\n",
    "        return out\n",
    "    \n",
    "class RNA_Transformer(nn.Module):\n",
    "    def __init__(self, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # token embs\n",
    "        self.token_emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # actual Encoder\n",
    "        self.layers = nn.ModuleList()\n",
    "        for _ in range(n_layers):\n",
    "            self.layers.append(EncoderBlock())\n",
    "        self.regression_head = nn.Linear(emb_dim, 2)\n",
    "        \n",
    "        # useful precompute for RoPE \n",
    "        freqs_cos, freqs_sin = precompute_freqs_cis(emb_dim//n_heads)\n",
    "        self.register_buffer(\"freqs_cos\", freqs_cos, persistent=False)\n",
    "        self.register_buffer(\"freqs_sin\", freqs_sin, persistent=False)\n",
    "        \n",
    "        # init weights\n",
    "        self.apply(self._init_weights)\n",
    "        for pn, p in self.named_parameters():\n",
    "            if pn.endswith('w3.weight') or pn.endswith('c_proj.weight'):\n",
    "                torch.nn.init.normal_(p, mean=0.0, std=0.02/math.sqrt(2 * n_layers))\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            \n",
    "    def forward(self, x, targets=None):\n",
    "        B, T = x.shape\n",
    "        z = self.dropout(self.token_emb(x))\n",
    "        freqs_cos, freqs_sin = self.freqs_cos[:T], self.freqs_sin[:T]\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            z = layer(z, freqs_cos, freqs_sin)\n",
    "        preds = self.regression_head(z)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            preds = preds.view(B*T, 2)\n",
    "            targets = targets.contiguous().view(B*T, 2).clamp(0, 1)\n",
    "            loss = F.l1_loss(preds, targets, reduction='none')\n",
    "            loss = loss[~loss.isnan()].mean()\n",
    "        return preds, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "744915cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T13:14:38.276791Z",
     "iopub.status.busy": "2023-10-13T13:14:38.276551Z",
     "iopub.status.idle": "2023-10-13T13:14:39.194261Z",
     "shell.execute_reply": "2023-10-13T13:14:39.192955Z"
    },
    "papermill": {
     "duration": 0.924609,
     "end_time": "2023-10-13T13:14:39.197935",
     "exception": false,
     "start_time": "2023-10-13T13:14:38.273326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = RNA_Dataset(train_2A3, train_DMS), RNA_Dataset(val_2A3, val_DMS)\n",
    "trainsampler = GroupLengthBatchSampler(RandomSampler(train_dataset), batch_size, drop_last=True)\n",
    "valsampler = GroupLengthBatchSampler(RandomSampler(val_dataset), batch_size, drop_last=True)\n",
    "trainloader = DataLoader(train_dataset, batch_sampler=trainsampler, collate_fn=collate_fn)\n",
    "validloader = DataLoader(val_dataset, batch_sampler=valsampler, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b91b18a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T13:14:39.208250Z",
     "iopub.status.busy": "2023-10-13T13:14:39.207297Z",
     "iopub.status.idle": "2023-10-13T13:14:45.064945Z",
     "shell.execute_reply": "2023-10-13T13:14:45.063973Z"
    },
    "papermill": {
     "duration": 5.86444,
     "end_time": "2023-10-13T13:14:45.067186",
     "exception": false,
     "start_time": "2023-10-13T13:14:39.202746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = RNA_Transformer() #torch.load(MODEL_PATH/\"best_model.pth\", map_location=device)\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc507bc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T13:14:45.073827Z",
     "iopub.status.busy": "2023-10-13T13:14:45.073244Z",
     "iopub.status.idle": "2023-10-13T13:14:45.078896Z",
     "shell.execute_reply": "2023-10-13T13:14:45.078093Z"
    },
    "papermill": {
     "duration": 0.010723,
     "end_time": "2023-10-13T13:14:45.080609",
     "exception": false,
     "start_time": "2023-10-13T13:14:45.069886",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 32\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4)\n",
    "train_steps = epochs * len(trainloader)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2907a062",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T13:14:45.086902Z",
     "iopub.status.busy": "2023-10-13T13:14:45.086159Z",
     "iopub.status.idle": "2023-10-14T00:24:22.903175Z",
     "shell.execute_reply": "2023-10-14T00:24:22.902072Z"
    },
    "papermill": {
     "duration": 40177.821995,
     "end_time": "2023-10-14T00:24:22.904899",
     "exception": false,
     "start_time": "2023-10-13T13:14:45.082904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with 12,596,994 parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 2583/2583 [20:31<00:00,  2.10it/s, Loss=0.184]\n",
      "100%|██████████| 136/136 [00:22<00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1817372590303421\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 2583/2583 [20:30<00:00,  2.10it/s, Loss=0.173]\n",
      "100%|██████████| 136/136 [00:22<00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.17070692777633667\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 2583/2583 [20:29<00:00,  2.10it/s, Loss=0.166]\n",
      "100%|██████████| 136/136 [00:22<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1646696776151657\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 2583/2583 [20:29<00:00,  2.10it/s, Loss=0.162]\n",
      "100%|██████████| 136/136 [00:22<00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.16041406989097595\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 2583/2583 [20:29<00:00,  2.10it/s, Loss=0.158]\n",
      "100%|██████████| 136/136 [00:22<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.15785320103168488\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 2583/2583 [20:32<00:00,  2.10it/s, Loss=0.156]\n",
      "100%|██████████| 136/136 [00:22<00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.15582484006881714\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 2583/2583 [20:30<00:00,  2.10it/s, Loss=0.154]\n",
      "100%|██████████| 136/136 [00:22<00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.15373042225837708\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 2583/2583 [20:31<00:00,  2.10it/s, Loss=0.152]\n",
      "100%|██████████| 136/136 [00:22<00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.15267890691757202\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 2583/2583 [20:31<00:00,  2.10it/s, Loss=0.15]\n",
      "100%|██████████| 136/136 [00:22<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.15117038786411285\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2583/2583 [20:31<00:00,  2.10it/s, Loss=0.148]\n",
      "100%|██████████| 136/136 [00:23<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.150384783744812\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 2583/2583 [20:31<00:00,  2.10it/s, Loss=0.148]\n",
      "100%|██████████| 136/136 [00:23<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.14920158684253693\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 2583/2583 [20:32<00:00,  2.10it/s, Loss=0.146]\n",
      "100%|██████████| 136/136 [00:22<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.14878380298614502\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 2583/2583 [20:31<00:00,  2.10it/s, Loss=0.145]\n",
      "100%|██████████| 136/136 [00:22<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.14823108911514282\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 2583/2583 [20:31<00:00,  2.10it/s, Loss=0.143]\n",
      "100%|██████████| 136/136 [00:22<00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.14787448942661285\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 2583/2583 [20:32<00:00,  2.10it/s, Loss=0.142]\n",
      "100%|██████████| 136/136 [00:22<00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.14741818606853485\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 2583/2583 [20:33<00:00,  2.09it/s, Loss=0.141]\n",
      "100%|██████████| 136/136 [00:22<00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.14682486653327942\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 2583/2583 [20:33<00:00,  2.09it/s, Loss=0.14]\n",
      "100%|██████████| 136/136 [00:22<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1465347409248352\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 2583/2583 [20:34<00:00,  2.09it/s, Loss=0.139]\n",
      "100%|██████████| 136/136 [00:22<00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.14632202684879303\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 2583/2583 [20:35<00:00,  2.09it/s, Loss=0.138]\n",
      "100%|██████████| 136/136 [00:22<00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.14593054354190826\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 2583/2583 [20:34<00:00,  2.09it/s, Loss=0.138]\n",
      "100%|██████████| 136/136 [00:22<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.14589837193489075\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 2583/2583 [20:34<00:00,  2.09it/s, Loss=0.136]\n",
      "100%|██████████| 136/136 [00:22<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1456979215145111\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 2583/2583 [20:33<00:00,  2.09it/s, Loss=0.136]\n",
      "100%|██████████| 136/136 [00:22<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.14532223343849182\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 2583/2583 [20:34<00:00,  2.09it/s, Loss=0.135]\n",
      "100%|██████████| 136/136 [00:22<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.14512145519256592\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 2583/2583 [20:33<00:00,  2.09it/s, Loss=0.134]\n",
      "100%|██████████| 136/136 [00:22<00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.14507274329662323\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 2583/2583 [20:35<00:00,  2.09it/s, Loss=0.133]\n",
      "100%|██████████| 136/136 [00:23<00:00,  5.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.14511717855930328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 2583/2583 [20:36<00:00,  2.09it/s, Loss=0.133]\n",
      "100%|██████████| 136/136 [00:23<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.14498642086982727\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 2583/2583 [20:36<00:00,  2.09it/s, Loss=0.132]\n",
      "100%|██████████| 136/136 [00:22<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.145013228058815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 2583/2583 [20:36<00:00,  2.09it/s, Loss=0.132]\n",
      "100%|██████████| 136/136 [00:23<00:00,  5.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.14491893351078033\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 2583/2583 [20:31<00:00,  2.10it/s, Loss=0.132]\n",
      "100%|██████████| 136/136 [00:22<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.14489144086837769\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 2583/2583 [20:32<00:00,  2.10it/s, Loss=0.132]\n",
      "100%|██████████| 136/136 [00:22<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1448107659816742\n",
      "Saving new best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 2583/2583 [20:30<00:00,  2.10it/s, Loss=0.131]\n",
      "100%|██████████| 136/136 [00:22<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.14484509825706482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 2583/2583 [20:25<00:00,  2.11it/s, Loss=0.132]\n",
      "100%|██████████| 136/136 [00:22<00:00,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.14489641785621643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def eval_loop():\n",
    "    model.eval()\n",
    "    losses = torch.zeros(len(validloader))\n",
    "    for i, (x, labels) in tqdm(enumerate(validloader), total=len(validloader)):\n",
    "        _, loss = model(x.to(device), labels.to(device))\n",
    "        losses[i] = loss.item()\n",
    "    model.train()\n",
    "    val_loss = losses.mean().item()\n",
    "    print(f\"Val Loss: {val_loss}\")\n",
    "    return val_loss\n",
    "            \n",
    "eval_distance = 500\n",
    "min_loss = 0.2\n",
    "n_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Training model with {n_params:,} parameters...\")\n",
    "loss_dict = {\"train_loss\": [], \"val_loss\": []}\n",
    "for epoch in range(epochs):\n",
    "    losses = torch.zeros(len(trainloader))\n",
    "    pbar = tqdm(enumerate(trainloader), total=len(trainloader))\n",
    "    pbar.set_description(f\"Epoch {epoch}\")\n",
    "    for i, (x, y) in pbar:\n",
    "        _, loss= model(x.to(device), y.to(device))\n",
    "        losses[i] = loss.item()\n",
    "        \n",
    "        if i >= eval_distance and i % eval_distance == 0:\n",
    "            train_loss = losses[i-eval_distance:i].mean().item()\n",
    "            pbar.set_postfix({\"Loss\":  train_loss})\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 3.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    val_loss = eval_loop()\n",
    "    if min_loss > val_loss:\n",
    "        print(\"Saving new best model...\")\n",
    "        min_loss = val_loss\n",
    "        torch.save(model, WORKING_PATH/\"best_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea2abd9",
   "metadata": {
    "papermill": {
     "duration": 4.012883,
     "end_time": "2023-10-14T00:24:31.030589",
     "exception": false,
     "start_time": "2023-10-14T00:24:27.017706",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## TODOS\n",
    "* Mask Padding in Attention\n",
    "* Deal with Duplicate Sequences in og data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 40238.621066,
   "end_time": "2023-10-14T00:24:38.144666",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-13T13:13:59.523600",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
